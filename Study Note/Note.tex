% default 12pt
\documentclass[12pt]{article}
 
% \usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,scrextend,bm}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage[margin=0.75in]{geometry}
\usepackage{pgfpages}
\usepackage{multicol}
% % For shrinking 4 pages to 1
% \pgfpagesuselayout{4 on 1}[a4paper, border shrink=0mm]
% 2 in 1
% \pgfpagesuselayout{2 on 1}[a4paper, border shrink=0mm, landscape]

\setlength{\parskip}{0em}
\setlist[enumerate]{itemsep=0mm}
\setlist[itemize]{itemsep = 0mm}

\theoremstyle{definition}
\newtheorem{definition}{DEFINITION}[subsection]


\pagestyle{fancy}

\let\newproof\proof
\renewenvironment{proof}{\begin{addmargin}[1em]{0em}\begin{newproof}}{\end{newproof}\end{addmargin}\qed}

\newtheorem{theorem}{THEOREM}[subsection]

\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\uline}[1]{\rule[0pt]{#1}{0.4pt}}
\newcommand{\trace}[1]{\text{tr}(#1)}
\newcommand{\Hom}{\text{Hom}}
\newcommand{\Maps}{\text{Maps}}
\newcommand{\image}{\text{im}}
\newcommand{\Mat}{\text{Mat}}
\newcommand{\suchthat}{\textit{ s.t. }}
\newcommand{\sgn}{\textbf{sgn}}
\newcommand{\adj}{\text{adj}}
\newcommand{\diag}{\text{diag}}
\newcommand{\transpose}[1]{#1^\mathsf{T}}
\newcommand{\Prob}[1]{\mathbb{P}(#1)}
\newcommand{\Expect}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\Var}[1]{\text{Var}\left[#1\right]}
\newcommand{\Cov}[1]{\text{Cov}\left(#1\right)}
\newcommand{\MonteCarlo}[1]{\hat{\mathbb{E}}\left[#1\right]}

%Set the course name here
\newcommand{\coursename}{Bayesian Theory}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{tcolorbox}
\tcbuselibrary{theorems}

\newtcbtheorem[number within=section]{mytheo}{Theorem}
{colback=red!5,colframe=red!35!black,fonttitle=\bfseries}{th}
\newtheorem{lemma}{LEMMA}[subsection]
\newtheorem{prop}{PROPOSITION}[subsection]
\newtheorem{corollary}{COROLLARY}[subsection]
\newtheorem{example}{EXAMPLE}[subsection]
 
\lhead{\coursename}
\rhead{Study Note}

\title{\coursename\\Study Note}
\author{Ian S.W. Ma}
\date{Winter 2020}

 
 
\begin{document}
\maketitle
% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------
\pagenumbering{gobble}
\tableofcontents
\newpage

\pagenumbering{arabic}
\setcounter{page}{1}

% Section 1
\section{Statistics Basics}
    \subsection*{General Structure: Probability Space/Triple}
    Probability Space/Triple $(\Omega, \mathcal{F}, \mathbb{P})$
    \begin{itemize}
        \item $\Omega$: \textbf{Sample Space}, set of all posible outcomes.
        \item $\mathcal{F}$: \textbf{Set of events \(\sigma\)}, each event is a subset of $\Omega$
        \item $\mathbb{P}$ Probability of event $\sigma \in \mathcal{F}$
    \end{itemize}
    \subsection*{Conditional Probability}
    Conditional probability of $A$ given $B$: $\Prob{A|B} = \frac{\Prob{A \cap B}}{\Prob{B}} \Leftrightarrow \Prob{A|B}\Prob{B} = \Prob{A \cap B}$
    \subsection*{General properties}
    \begin{itemize}
        \item $\Prob{A \cup B} = \Prob{A} + \Prob{B} - \Prob{A \cap B}$
            \subitem Events are mutually exclusive $\Rightarrow \Prob{A \cap B} = 0$
        \item $\Prob{A \cap B} = \Prob{A|B}\Prob{B}$
            \subitem Events are independent $\Rightarrow \Prob{A|B} = \Prob{A}$
        \item Law of Total Probability
            \subitem If events $A_1, A_2, A_N$ are mutually exclusive and exhaustive ($\bigcup_{i = 1}^N A_i = \Omega$) then:
            $$\Prob{B} = \sum_{i=1}^N \Prob{A_i \cap B} = \sum_{i=1}^N \Prob{B|A_i}\Prob{A_i}$$
    \end{itemize}
    \subsection*{Random Variables}
    \begin{tabular}{|c|c|c|}
        \hline
        $X \sim$ Distribution & $\Expect{X}$ & $\Var{X}$\\
        \hline
        Normal$(\mu, \sigma^2)$ & $\mu$ & $\sigma^2$\\
        \hline
        Bernoulli$(\theta)$ & $\theta$ & $\theta(1-\theta)$\\
        \hline
        Binomial$(\theta)$ & $n\theta$ & $n\theta(1-\theta)$\\
        \hline
        Poisson$(\mu)$ & $\mu$ & $\mu$\\
        \hline
        Uniform$(\alpha, \beta)$ & $\frac{\alpha + \beta}{2}$ & $\frac{(\alpha + \beta)^2}{12}$\\
        \hline
        Beta$(\alpha, \beta)$ & $\frac{\alpha}{\alpha + \beta}$ & $\frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta+1)}$\\
        \hline
        Gamma$(\alpha, \beta)$ & $\frac{\alpha}{\beta}$ & $\frac{\alpha}{\beta^2}$\\
        \hline
        Inv. Gamma$(\alpha, \beta)$ & $\frac{\beta}{\alpha -1}$ & $\frac{\beta^2}{(\alpha-1)^2(\alpha -2)}$\\
        \hline
        Exponential$(\lambda)$ & $\frac{1}{\lambda}$ & $\frac{1}{\lambda^2}$\\
        \hline
    \end{tabular}
    \subsection*{Random Vectors}
    \begin{tabular}{|c|c|c|c|}
        \hline
        $\mathbf{X} = X_1,...,X_k \sim$ Distribution & $\Expect{X_i}$ & $\Var{X_i}$ & $\Cov{X_i,X_j}$\\
        \hline
        Multivariative Normal$(\bm{\mu}, \Sigma)$ & $\mu_i$ & $\Sigma_{i,i}$ & $\Sigma_{i,j}$\\
        \hline
        Multinomial$(n,\theta_1,...,\theta_k)$ & $n\theta_i$ & $n(1-\theta_i)$ & $-n\theta_i\theta_j$\\
        \hline
    \end{tabular}


\pagebreak
\section{Bayes Throrem}
    \subsection*{Discrete Case}
    \begin{align*}
        \Prob{X=x_i| Y = y_j} &= \frac{\Prob{X = x_i, Y = y_j}}{\Prob{Y = y_j}}\\
        &= \frac{\Prob{Y = y_j|X=x_i} \Prob{X = x_i}}{\Prob{Y = y_j}}\\
        &= \frac{\text{Likelihood}\times \text{Prior}}{\text{Marginal}}\\
        &= \frac{\Prob{Y = y_j|X=x_i} \Prob{X = x_i}}{\sum_{k=1}^n\Prob{X = x_k,Y = y_j}}\\
        &= \frac{\Prob{Y = y_j|X=x_i} \Prob{X = x_i}}{\sum_{k=1}^n\Prob{Y = y_j|X = x_k}P(X = x_k)}\\
        \Rightarrow \Prob{(X|Y)} &= \frac{\Prob{Y|X} \Prob{X}}{\sum_x \Prob{X = x,Y}} = \frac{\text{Likelihood}\times \text{Prior}}{\text{Marginal}} 
    \end{align*}
    \subsection*{Continous Case}
        $$f(X|Y) = \frac{f(X,Y)}{g(Y)} = \frac{g(Y|X) f(X)}{\int g(Y|X)f(X) dX}$$

\subsection*{Bayesian Statistical Inference}
\begin{itemize}
    \item $L(\theta|y) = f(y|\theta)$: Likelihood
    \item $\pi(\theta)$: Prior
    \item $m(y) = p(y)$: Marginal distribution/Normalizing constant
\end{itemize}
$$\text{Posterior Distribution: } p(\theta|y) = \frac{f(y|\theta)\pi(\theta)}{\int p(\theta,y)d\theta} = \frac{f(y|\theta)\pi(\theta)}{\int f(y|\theta)\pi(\theta) d\theta} \propto f(y|\theta)\pi(\theta)$$
\subsection*{Predictive Distrubutions}
\begin{align*}
    \text{Prior Predictive Distribution} &\text{:} &p(y^{new}) &= \int_\theta f(y^{new}|\theta)\pi(\theta)d\theta\\
    \text{Posterior Predictive Distribution} &\text{:} &p(y^{new}|y^{old}) &= \int_\theta f(y^{new}|\theta,y^{old})p(\theta|y^{old})d\theta
\end{align*}
\subsection*{Bayes Theorem for Multiple Parameters $\Theta = \{\theta_1,...,\theta_q\}$}
$$\Prob{\Theta|\bm{y}} = \frac{\Prob{\bm{y}|\Theta}\Prob{\Theta}}{\Prob{\bm{y}}} \propto \Prob{\bm{y}|\Theta}\Prob{\Theta}$$

% Week 2 
\newpage
\section{Conjugate Priors}
\begin{center}
    \begin{tabular}{|l|c|l|}
        \hline
        Sample Distribution & Parameter & Prior\\
        \hline\hline
        Bernoulli$(\theta)$ & $\theta$ & Beta$(\alpha,\beta)$\\
        \hline
        Binomial$(n,\theta)$ & $\theta$ & Beta$(\alpha,\beta)$\\
        \hline
        Poisson$(\theta)$ & $\theta$ & Gamma$(\alpha,\beta)$\\
        \hline
        Exponential$(\theta)$ & $\theta$ & Gamma$(\alpha,\beta)$\\
        \hline
        Normal$(\mu,\sigma_0^2)$ & $\mu$ & Normal$(\mu_h,\sigma_h^2)$\\
        \hline
        Normal$(\mu_0,\sigma^2)$ & $\sigma^2$ & Inverse Gamma$(\alpha,\beta)$\\
        \hline
        Normal$(\mu_0,1/\tau)$ & $\tau = 1/\sigma^2$ & Gamma$(\alpha,\beta)$\\
        \hline
        Multinomial$(n,\theta_1,...,\theta_k)$ & $\theta_1,...,\theta_k$ &  Dirichlet$(\alpha_1,...,\alpha_k)$\\
        \hline
        Uniform$(0,\theta)$ & $\theta$ & Pareto$(\theta_m,\alpha)$\\
        \hline
    \end{tabular}
\end{center}
\section{Normal Distribution Priors}
    \subsection*{Unknown $\mu$, known $\sigma^2$}
    \begin{itemize}
        \item Sample $\bm{y} \in \mathbb{R}^n$
        \item Prior $\mu \sim \text{Normal}(\mu_0,\sigma_0^2) = \text{Normal}\left(\mu_0,\frac{\sigma^2}{m}\right) \Rightarrow m = \sigma^2/\sigma_0^2$
        \item Posterior: $$\mu|\bm{y},\sigma^2 \sim \text{Normal}\left( \frac{m\mu_0 + n\bar{y}}{m+n} , \frac{\sigma^2}{m+n} \right) = \text{Normal}\left( (1-w)\mu_0 + w\bar{y} , \frac{\sigma^2}{m+n} \right)$$
            $w = \frac{m}{m+n}$
    \end{itemize}
    \subsection*{Unknown $\mu$, known $\tau$}
    \begin{itemize}
        \item Sample $\bm{y} \in \mathbb{R}^n$
        \item Prior $\mu \sim \text{Normal}\left(\mu_0,\frac{\sigma^2}{m}\right) = \text{Normal}\left(\mu_0,\frac{1}{\tau m}\right)$
        \item Posterior: $$\mu|\bm{y},\sigma^2 \sim \text{Normal}\left( \frac{m\mu_0 + n\bar{y}}{m+n} , \frac{1}{\tau(m+n)} \right) = \text{Normal}\left( (1-w)\mu_0 + w\bar{y} , \frac{1}{\tau(m+n)} \right)$$
            $w = \frac{m}{m+n}$
    \end{itemize}
    \subsection*{Unknown $\tau$, known $\mu$}
    \begin{itemize}
        \item Sample $\bm{y} \in \mathbb{R}^n$
        \item Prior $\tau \sim \text{Gamma}(\alpha,\beta)$
        \item Posterior: $$\tau|\bm{y},\mu \sim \text{Gamma}\left(\alpha + \frac{n}{2}, \beta + \frac{z^2}{2}\right)$$
            $z^2 = \sum_i(y_i - \mu)^2$
    \end{itemize}
    \subsection*{Unknown $\sigma^2$, known $\mu$}
    \begin{itemize}
        \item Sample $\bm{y} \in \mathbb{R}^n$
        \item Prior $\mu,\sigma^2 \sim \text{Normal}\left(\mu_0, \frac{\sigma^2}{\kappa}\right) \times \text{Inverse Gamma}(\alpha, \beta)$
        \item Posterior: $$\mu, \sigma^2|\bm{y} \sim \text{Normal}\left(\frac{\kappa\mu_0 + n\bar{y}}{\kappa + n},\frac{\sigma^2}{\kappa + n}\right) \times \text{Inverse Gamma}\left(\alpha + \frac{n}{2}, \beta + \frac{(n-1)s^2}{2} + \frac{\kappa n(\bar{y} - \mu_0)^2}{2(\kappa + n)}\right)$$
            $s^2 = \sum_i(y_i - \bar{y})^2/(n-1)$\\
            $\kappa = \sigma^2(\alpha-1)/\beta$ or given (seriously it's not written anywhere Ken, I'm just guessing here man)
    \end{itemize}

% Week 4
\section{Jeffrey's Prior}
    \subsection*{Definition}
    Jeffery Prior: $\pi_{JP}(\theta) \propto \sqrt{I(\theta|y)}$
    \\Fisher Information:
    $$I(\theta|y) = \Expect{\left( \frac{d \log f(y|\theta)}{d\theta} \right)^2} = -\Expect{ \frac{d^2 \log f(y|\theta)}{d\theta^2}}$$
    \subsection*{1:1 transformation of Jeffrey's Prior}
    $$\pi(\phi) = \pi_{JP}(\theta)\left| \frac{d \theta}{d \phi}\right|$$
    \subsection*{Jeffrey's Prior for Multivariate Parameter Vector}
    Gradient of log likelihood:
    $$ S(\bm{\theta}) = \begin{bmatrix*}
        \partial_{\theta_1} \log f(x)\\
        \vdots\\
        \partial_{\theta_n} \log f(x)
    \end{bmatrix*}$$
    Hessian Matrix of log likelihood:
    $$H(\bm{\theta}) = \text{Jacobian}\left[S(\bm{\theta})\right] = \begin{bmatrix*}
        \partial_{\theta_1}\partial_{\theta_1} \ln f(x) & \cdots & \partial_{\theta_1}\partial_{\theta_n} \ln f(x)\\
        \vdots & \ddots & \vdots\\
        \partial_{\theta_n}\partial_{\theta_1} \ln f(x) & \cdots & \partial_{\theta_n}\partial_{\theta_n} \ln f(x)
    \end{bmatrix*}$$
    Fisher Information: $I(\theta|x) = -\Expect{H(\theta)}$\\
    Jeffrey's Prior: $\pi_{JP} \propto \sqrt{\det(I(\theta|x))}$

\newpage
\section{Reference Prior}
    \subsection*{Kullback-Leibler  (KL)  divergence}
    A measure of the difference between two pmfs/pdfs. When $KL(f,g) = 0$, the two distributions are idetical.
        \subsubsection*{Properties}
        \begin{itemize}
            \item $KL(f,g) \neq KL(g,f)$
            \item $KL(fmg) \geq 0$
        \end{itemize}
        \subsubsection*{Continous parameter $x$}
        $$KL(f,g) = \int \ln\left[\frac{f(x)}{g(x)}\right]dx = \mathbb{E}_f[\log f(X)] - \mathbb{E}_g[\log f(X)]$$
        \subsubsection*{Discrete parameter $x$}
        $$KL(f,g) = \sum_{x\in X} \ln\left[\frac{f(x)}{g(x)}\right] = \mathbb{E}_f[\log f(X)] - \mathbb{E}_g[\log f(X)]$$
    \subsection*{Reference Prior} Read week 4 notes (2.2)

% Week 5
\section{Point Estimates}
	\subsection*{Components of Decision Theory with emphasis on parameter estimation}
		\begin{itemize}
			\item State Spcae $\Theta$, unknown true value $\theta \in \Theta$
			\item Action Space $\mathcal{A} \ni a$, sometimes $\mathcal{A} = \Theta$
			\item Sampling Distribution $f(\bm{y}| \theta)$
			\item Loss Function $\mathcal{L}(a|\theta)$
			\item Risk $R_\theta(a|\bm{y}) = \mathbb{E}_\theta[L(a|\theta,y)] = \int_{\theta \in \Theta} \mathcal{L}(a|\theta)p(\theta|\bm{y})d\theta$
			\item Bayes Estimator of a parameter $\hat{\theta}_{BE} = \argmin_{\hat{\theta} \in \Theta} R_\theta(\hat{\theta}|\bm{y})$
		\end{itemize}
	\subsection*{Common Loss Functions and Corresponding Estimators}
	 \begin{itemize}
		 \item \textbf{Squared Error Loss}: $\mathcal{L}(\theta|\hat{\theta}) = (\theta - \hat{\theta})^2$, Bayes Estimator $\hat{\theta} = \Expect{\theta|\bm{y}}$
		 \item \textbf{Absolute Error Loss}: $\mathcal{L}(\theta|\hat{\theta}) = |\theta - \hat{\theta}|$, Bayes Estimator $\hat{\theta} = \theta_{0.5}$, ($\Prob{\theta \leq \theta_{0.5}} = 0.5$)
		 \item \textbf{0-1 Loss}: $\mathcal{L}(\theta|\hat{\theta}) = I(\theta \neq \hat{\theta})$, Bayes Estimator $\hat{\theta}$ is the posterior mode
	 \end{itemize}

\newpage
\section{Interval Estimates}
	$$P\times 100\% \text{ Bayesian Credible interval} =[LB, UB] \text{ where } \int_{LB}^{UB} p(\theta,\bm{y})d\theta = P$$
	If loooking for one side-confidence bounds then $LB = -\infty$ or $UB = \infty$
	\subsection*{Symmetric Credicble Interval}
		$$[LB,UB] \text{ where } \Prob{\theta \leq LB} = \Prob{\theta \geq UB} = \alpha/2 = (1-P)/2$$
	\subsection*{Highest Posterior Density Interval (HPDI)}
		Credible Interval where all values outside the interval has a density smaller than any of the values in the interval.
	\subsection*{Credible Regions}
        $$\iint p(\theta_1, \theta_2| \bm{y})d\theta_1 d\theta_2 = 1 - \alpha = P$$ 

\section{Classic Hypothesis Testing}
    \begin{enumerate}
        \item Assume hypothesis $H_0$ is true
        \item Calculate test statistic $T(\bm{y}_{obs})$ based on observed sample data regarding to $H_0$ and $H_1$
        \item Conditional on $H_0$ being true, $p$-value $= \Prob{T(\bm{y})\text{ more extreme than } T(\bm{y}_{obs})|\theta, H_0}$
        \item Reject $H_0$ and accept $H_1$ for sufficiently small $p$-values, do not reject $H_0$ otherwise
    \end{enumerate}

\section{Bayesian Hypothesis Testing}
Suppose there are tow hypotheses about parameter $\theta$:
$$H_0:\theta \in \Theta_1 \quad H_1:\theta \in \Theta_1$$
where $\Theta_0 \cup \Theta_1 = \Theta$ and $\Theta_0 \cap \Theta_1 = \emptyset$.
\\~\\
The Bayesian approach specifies prior probabilities on each hypotheses:
\begin{align*}
    p_0 &= \Prob{H_0 \text{ is true}} = \Prob{\theta \in \Theta_0}\\
    p_1 &= \Prob{H_1 \text{ is true}} = \Prob{\theta \in \Theta_1}
\end{align*}
Where the posteriors are as follows:
\begin{align*}
    \Prob{H_0|\bm{y}} &= \Prob{\theta \in \Theta_0|\bm{y}}\\
    \Prob{H_1|\bm{y}} &= \Prob{\theta \in \Theta_1|\bm{y}}
\end{align*}
Where $\Prob{H_0|\bm{y}} + \Prob{H_1|\bm{y}} = 1$
\newpage
\subsection*{Simple}
\begin{itemize}
    \item Single parameter values $H_0:\theta = \theta_0 \quad H_1:\theta = \theta_1$
    \item Posteriors:
        \begin{align*}
            \Prob{H_0|\bm{y}} &= \Prob{\theta = \theta_0|\bm{y}} = \frac{f(\bm{y}|\theta_0)p_0}{m(\bm{y})} = \frac{f(\bm{y}|\theta_0)p_0}{f(\bm{y}|\theta_0)p_0 + f(\bm{y}|\theta_1)p_1}\\
            \Prob{H_1|\bm{y}} &= \Prob{\theta = \theta_1|\bm{y}} = \frac{f(\bm{y}|\theta_1)p_1}{m(\bm{y})} = \frac{f(\bm{y}|\theta_1)p_1}{f(\bm{y}|\theta_0)p_0 + f(\bm{y}|\theta_1)p_1}\\
            \Prob{H_0|\bm{y}} &= 1 - \Prob{H_1|\bm{y}}
        \end{align*}
    \item posterior odds of $H_0$ against $H_1$:
        $$\frac{\Prob{H_0|\bm{y}}}{\Prob{H_1|\bm{y}}} = \frac{f(\bm{y}|\theta_0)p_0}{f(\bm{y}|\theta_1)p_1}$$
\end{itemize}
\subsection*{Composite}
\begin{itemize}
    \item Single parameter values $H_0:\theta \in \Theta_0 \quad H_1:\theta \in \Theta_1$
    \item Prior: $p_i = \int_{\theta \in \Theta_i}\pi(\theta) d\theta$
    \item Posteriors:
        \begin{align*}
            \Prob{H_i|\bm{y}} &= \frac{p(\bm{y},H_i)}{m(\bm{y})} = \frac{p_i\ p(\bm{y}|H_i)}{m(\bm{y})} = \frac{p_i\int p(\bm{y},\theta|H_i)d\theta}{m(\bm{y})} = \frac{p_i\int f(\bm{y}|\theta)\pi(\theta|H_i) d\theta}{m(\bm{y})}\\
            &= \frac{p_i\int_{\theta \in \Theta_i} f(\bm{y}|\theta)\frac{\pi(\theta)}{p_i} d\theta}{m(\bm{y})} = \frac{\int_{\theta \in \Theta_i} f(\bm{y}|\theta)\pi(\theta) d\theta}{m(\bm{y})} = \int_{\theta \in \Theta_i} p(\theta|\bm{y}) d\theta = \Prob{\theta \in \Theta_i|\bm{y}}
        \end{align*}
    \item posterior odds of $H_0$ against $H_1$:
        $$\frac{\Prob{H_0|\bm{y}}}{\Prob{H_1|\bm{y}}} = \frac{\int_{\theta \in \Theta_0}f(\bm{y}|\theta) \pi(\theta)d\theta}{\int_{\theta \in \Theta_1}f(\bm{y}|\theta) \pi(\theta)d\theta} = \frac{\Prob{\theta \in \Theta_0|\bm{y}}}{\Prob{\theta \in \Theta_1|\bm{y}}} = \frac{\Prob{\theta \in \Theta_0|\bm{y}}}{1-\Prob{\theta \in \Theta_0|\bm{y}}}$$
\end{itemize}
\subsection*{Multiple models}
\begin{itemize}
    \item Set of models $M_1,...,M_K$
    \item $H_i$: The correct model is $M_i$
    $$\Prob{H_i|\bm{y}} = \frac{\Prob{H_i, \bm{y}}}{\Prob{\bm{y}}} = \frac{\Prob{H_i, \bm{y}}}{\sum_{j=1}^K \Prob{H_j,\bm{y}}}$$
\end{itemize}
\newpage
\section*{Bayes Factor}
\begin{itemize}
    \item Prior odds for $H_0$ against $H_1 = {p_0}/{p_1}$
    \item Posterior odds for $H_0$ against $H_1 = \Prob{H_0|\bm{y}}/\Prob{H_1|\bm{y}}$
    \item Bayes Factor for $H_0$ against $H_1$:
        \begin{align*}
            BF_{01} &= \frac{\text{Posterior odds for $H_0$ against $H_1$}}{\text{Prior odds for $H_0$ against $H_1$}} = \frac{\Prob{H_0|\bm{y}}/\Prob{H_1|\bm{y}}}{p_0/p_1}\\
            BF_{10} &= \frac{1}{BF_{01}}
        \end{align*}
\end{itemize}
\begin{center}
    \begin{tabular}{|c|r|}
        \hline
        $BF_{ij}$ & Interpretation\\
        \hline\hline
        $<3$ & No edvidence for $H_i$ over $H_j$\\
        $>3$ & Positive edvidence for $H_i$\\
        $>20$ & Strong edvidence for $H_i$\\
        $>150$ & Very strong edvidence for $H_i$\\\hline
    \end{tabular}
\end{center}
    \subsubsection*{Simple $H_0$ vs Simple $H_1$}
    $$BF_{01} = \frac{\Prob{H_0|\bm{y}}/\Prob{H_1|\bm{y}}}{p_0/p_1} = \frac{(f(\bm{y}|\theta_0)p_0)/(f(\bm{y}|\theta_1)p_1)}{p_0/p_1} = \frac{f(\bm{y}|\theta_0)}{f(\bm{y}|\theta_1)}$$
    \subsubsection*{Composite $H_0$ vs Composite $H_1$}
    $$BF_{01} = \frac{\Prob{H_0|\bm{y}}/\Prob{H_1|\bm{y}}}{p_0/p_1} = \frac{\left[ \int_{\theta \in \Theta_0} f(\bm{y}|\theta)\pi(\theta) d\theta \right] / \left[ \int_{\theta \in \Theta_1} f(\bm{y}|\theta)\pi(\theta) d\theta \right]}{p_0/p_1} = \frac{\Prob{\theta \in \Theta_0|\bm{y}} / \Prob{\theta \in \Theta_1|\bm{y}}}{p_0/p_1} $$
    \subsubsection*{Simple $H_0$ vs Composite $H_1$}
    $$BF_{01} = \frac{\Prob{H_0|\bm{y}}/\Prob{H_1|\bm{y}}}{p_0/p_1} = \frac{\left[ f(\bm{y}|\theta_0)p_0 \right]/ \left[ p_1 \int_{-\infty}^\infty f(\bm{y}|\theta)\pi(\theta) d\theta \right]}{p_0/p_1} = \frac{f(\bm{y}|\theta_0)}{\int_{-\infty}^\infty f(\bm{y}|\theta)\pi(\theta)d\theta} = \frac{f(\bm{y}|\theta_0)}{m(\bm{y})}$$
    \subsubsection*{Multipes Hypotheses}
    Read 5B.7 cba to type

\section{Deterministic Numerical Integration}
$$\int_{x_i}^{x_{i+m}} f(x) dx \approx \sum_{j=1}^m w_{ij} f(x_{i+j})$$

\newpage
\section{Monte Carlo Integration}
\begin{align*}
    \text{Expectaqtion }\Expect{\theta} &= \int\theta p(\theta) d\theta\\
    \text{Samples of } \theta &: \theta_1,...,\theta_N\\
    \Rightarrow \text{Monte Carlo Estimate } \hat{\mathbb{E}}[\theta] &= \frac{1}{N}\sum_{i=1}^N \theta_i \approx \Expect{\theta}
\end{align*}
By the Law of Large Numbers, $\Prob{\lim_{N \rightarrow \infty} \hat{\mathbb{E}}\left[\theta\right] = \Expect{\theta}} = 1$.
\\~\\
Many Bayesian integrals can be viewed as expectations, such as probabilities and normalising constants.

\subsection*{Direct Sampling}
\begin{itemize}
    \item Target Distribution, often the posterior $p(\theta|\bm{y})$
    \item Integrals of interest: $\Expect{h(\theta|\bm{y})} = \int h(\theta)p(\theta|\bm{y}) dy$
    \begin{itemize}[topsep = 0pt]
        \item Common choises for $h(\theta):$
         \subitem $h(\theta) = \theta$, the posterior mean
         \subitem $h(\theta) = (\theta - \Expect{\theta})^2$, the posterior variance
         \subitem $h(\theta) = I(a \leq \theta \leq b)$, $\Prob{\theta \in [a,b]}$
    \end{itemize}
    \item Samples $\theta_1,...,\theta_N$
    \item Monto Carlo estimation of Integrals of interest $\Expect{h(\theta| \bm{y})} \approx \MonteCarlo{h(\theta| \bm{y})} = \frac{1}{N}\sum h(\theta_i)$
    \item Monte Carlo Error $= \MonteCarlo{h(\theta|\bm{y})} - \Expect{h(\theta|\bm{y})}$ 
\end{itemize}

\subsection*{Inverse Probability Integral Transform Method (Inverse PIT)}
\subsubsection*{Continous Random Variable}
    \begin{itemize}
        \item Let $Y$ be continous random variables with cdf $F_Y(y) \in  [0,1]$
        \item Define new random variable $U = F_Y(Y) \sim \text{Uniform}(0,1)$
    \end{itemize}
    \subparagraph*{The Inverse PIT method}
    \begin{itemize}
        \item Transform a uniform variable $U$ using the inverse CDF of $Y$ ($g(U) = F_Y^{-1}(U)$). $g \sim Y$
        \item Therefore if one can evaluate $F^{-1}$ for $Y$, then sample $y$ can be generated by $y = F^{-1}(u)$, where $u \sim \text{Uniform}(0,1)$
    \end{itemize}
\subsubsection*{Discrete Random Variable}
    \subparagraph*{The Inverse PIT method}
    \begin{itemize}
        \item Same for Continous method where:$$F^{-1}(u) = \min_y\{y:F_Y(y)\geq u\}$$
    \end{itemize} 

\newpage
\subsection*{Rejection Sampling}
Target distribution $p(\theta|\bm{y})$
\begin{itemize}
    \item Generates independent samples form envelope distribution $g(\theta)$
    \item Only some generated values are kept/used, while the rest are discarded
    \item Often used for generating univariate random variables than a multivariate random vector
\end{itemize}
    \subsubsection*{General Rejection Algorithm}
    For target distribution $p()\theta$ and envelope $g(\theta)$, the (upper) bound $M$ pf $p/g$ is defined:
    $$M \geq \frac{p(\theta)}{g(\theta)} \quad \forall \theta \Leftrightarrow M(g)\theta \geq p(\theta)$$
    The Algorithm to generate a single value form $p(\theta)$ is as follows:
    \begin{enumerate}
        \item Generate $\theta^*$ from $g(\theta^*)$
        \item Generate $u$ form Uniform$(0,Mg(\theta^*))$
        \item If $u \leq p(\theta^*)$ keep $\theta^*$ else reject and return step 1
    \end{enumerate}
    The acceptance rate is $\frac{1}{M}$ which $M$ is defined as above. For optimal acceptance rate, we choose $M_{opt} = \sup\left\{\frac{p(\theta)}{g(\theta)}\right\}$

\subsection*{Importance Sampling}
    Simlar to Rejection sampling. However, we adjust the values to correspond to the rightr distribution instead of rejecting them. Therefore all generated $\theta$ are kept, there's no rejection.
    \\~\\Suppose there is another distribution has the same support as $p(\theta|\bm{y})$, the integral then can be written as $\mathbb{E}_p[h(\theta|\bm{y})] = \mathbb{E}_g[h(\theta)w(\theta)]$ where $w(\theta) = p(\theta|\bm{y})/g(\theta)$ is the \textbf{importance ratio}.
    \\~\\ The Monte Carlo estimats can be calculated $\hat{\mathbb{E}}_p[h(\theta|\bm{y})] \equiv \hat{\mathbb{E}}_g[h(\theta)w(\theta)] = \frac{1}{N}\sum h(\theta^i)w(\theta^i)$

\subsection*{Sampling Importance Re-Sampling}
\subsubsection*{Algorithm for generating a samplem sixe of $n$}
\begin{enumerate}
    \item Choosing $N > n$. generate $N$ samples of $\theta^i, i = 1,...,N$ form the envolope distribution (importance sampler) $g(\theta)$
    \item Calculate the importance ratio $w_i = p(\theta^i|\bm{y})/g(\theta)$, then scale by the some of weights:
        $$w^{*i} = \frac{w^i}{\sum_j^N w^j}$$
    \item randomly sample $n$ $\theta^i$'s with replacement, with probabilities $w^{*1},...,w^{*N}$
\end{enumerate}

\newpage
\section{Markov Chain Monte Carlo (MCMC)}
    \subsection*{Overwiew}
        \begin{itemize}
            \item \textbf{Dependent Samples}: $\theta|\bm{y}$
            \item \textbf{Iterative Conditional Generation}: $g(\theta^{i}|\theta^{i-1})$
            \item \textbf{Burn-in}: The initial vales $\theta^1,...,\theta^B$ are not distributed according to th target distribution $p(\theta)$, therefore would be discarded
            \item \textbf{Sample for Inference}: The additional $N - B$ samples $\theta^{B+1},...,\theta^N$ are used for inference
        \end{itemize}
    \subsection*{Markov Chain}
        \begin{itemize}
            \item \textbf{State Space} $S$: is a set of all possible states $j$
            \item \textbf{Process} $\theta^t = j$: process at time $t$ is in state $j$
        \end{itemize}
        \subsubsection*{Definition}
        \begin{align*}
            \Prob{\theta^0 = x_0,..., \theta^T = x_T} &= \Prob{\theta^T = x_T|\theta^0 = x_0,...,\theta^{T-1} = x_{T-1}}\\
                &\times \Prob{\theta^{T-1} = x_{T-1}|\theta^0 = x_0,...,\theta^{T-2} = x_{T-2}}\\
                &\times \Prob{\theta^0 = \theta_0}
        \end{align*} 
        \textbf{Markov Peoperty}: if $\theta^t|\theta^{t-1}$ is independent to other values, then\\$\Prob{\theta^T = x_T|\theta^0 = x_0,...,\theta^{T-1} = x_{T-1}} = \Prob{\theta^T = x_T|\theta^{T-1} = x_{T-1}}$. Therefore:
        $$\Prob{\theta^0 = x_0,..., \theta^T = x_T} = \prod_{t=1}^T\Prob{\theta^{t} = x_t|\theta^{t-1} = x_{t-1}} \times \Prob{\theta^0 = x_0}$$
        The sequence of random variables $\theta^1,..., \theta^K$ with Markov Property is a Markov Chain
        \subsubsection*{Terminology and Notation}
        \begin{itemize}
            \item \textbf{One-Step Transistion Probability} $p_{ij}^t = \Prob{\theta^t = j|\theta^{t-1} = i}$
            \item if $p_{ij}^t = p_{ij}\ \forall t$ then the chain is \textbf{time homogeneous} otherwise \textbf{time imhomogeneous}
            \item \textbf{Transistion probability matrix} $(P_t)_{ij} = p_{ij}$, where each row sums to one 
                \subitem for a time homogeneous chain $P_t = P \ \forall t$
        \end{itemize}
        \newpage
        \subsubsection*{Limiting Behaviour of Markov Chain}
        \begin{itemize}
            \item \textbf{Recurrent State}: state where a Markov Chain returns with probability 1
            \item \textbf{Nonnull State}: state where it will eventually recurrence in a finite ecpected time
            \item \textbf{Irreducible Markov Chain}: $\exists m \in \mathbb{N} \suchthat \Prob{\theta^{m +n} = j| \theta^n = i} > 0 \ \forall i$
            \item \textbf{Periodic Markov Chain}: $\exists m \in \mathbb{N} \suchthat \exists d \in \mathbb{d} \suchthat \Prob{\theta^{m +n} = j| \theta^n = i} > 0 \cap m/d \in \mathbb{Z^+}  \ \forall i$
                \subitem otherwise \textbf{Aperiodic Markov Chain}
            \item \textbf{Ergodic Markov Chain}: \textbf{Irreducible}, \textbf{aperiodic}, all states are \textbf{nonnull} and \textbf{recurrent}
        \end{itemize}
        \subsubsection*{Marginal amd Stationary Distributoin}
        \begin{itemize}
            \item \textbf{Marginal Probability Distribution} for state at time $t$ is denoted $\bm{\pi}_t$, which is a vector of probabilities that sum to one
            \item $(\pi_t)_i = \bm{\pi}_t(i) = \Prob{\theta^t = i}$
            \item $\bm{\pi}_{t+1}^\top = \bm{\pi}_{t}^\top P \Leftrightarrow \bm{\pi}_{t+1} = P^\top \bm{\pi}_{t}$
            \item If $\bm{\pi}^\top P = \bm{\pi}^\top$ then $\bm{\pi}$ is a \textbf{stationa distribution}
        \end{itemize}
        \subsubsection*{Reversible Markov Chain}
        If a time homogeneous Markov Chain with tpm $P$ and Stationary distribution $\bm{\pi}$ fufill the \textbf{Detailed Balance equation} then it is a reversible Markov Chain.
        \\~\\\textbf{Detailed Balance equation} is written $\bm{\pi}(i)p_{ij} = \bm{\pi}(j)p_{ji}$
        \subsubsection*{Key Theoretical Results}
        If a Markov Chain with tpm $P$ and is irreducible, aperiodic and has a stationary distribution $\bm{\pi}$, the the followings are true:
        \begin{itemize}
            \item $\bm{\pi}$ is unique, $\exists! \bm{\pi} \suchthat \bm{\pi}^\top P = \bm{\pi}^\top$
            \item $\lim_{n \rightarrow \infty} \Prob{\theta^{t+n} = j| \theta^t = i} = \bm{\pi}(j)$
            \item $\bm{\pi}$ is the follows solution to the following program:
                \begin{align*}
                    \sum_{i \in S} \bm{\pi}(i) &= 1\\
                    \bm{\pi}(j) &= \sum_{i \in S} \bm{\pi}(i)p_{ij}\\
                    \text{Subject to} &: \bm{\pi}(j) \geq 0 \ \forall j \in S
                \end{align*}
        \end{itemize}

\newpage
\section{Metropolis-Hasting Algorithm}
    \subsection*{Steps}
    Iteration $t$ gievn sample $\Theta^{t-1}$:
    \begin{enumerate}
        \item Generate candidate value $\Theta^c$ from proposal distribution $q(\Theta^c|\Theta^{t-1})$
        \item Calculate Metropolis Hasting Ratio (MHR) aka. accpetance rate if $< 1$:
        $$\text{MHR}(\Theta^{t-1}, \Theta^C) = \frac{p(\Theta^c)q(\Theta^{t-1}|\Theta^c)}{p(\Theta^{t-1})q(\Theta^c|\Theta^{t-1})}$$
        \item Generate $u \sim \text{Uniform}(0,1)$
        \item if $u \leq \min(1,\text{MHR}(\Theta^{t-1}, \Theta^C))$, then $\Theta^t = \Theta^c$ (Keep $\Theta^c$) Otherwise $\Theta^t = \Theta^{t-1}$
        \item Set $t = t+1$, return step 1
    \end{enumerate}
    \subsection*{Special case proposals}
        \subsubsection*{Random walks ($\theta^c = \theta^c + \epsilon$)}
        Special cases for $\epsilon$: $\epsilon \sim \begin{cases}
            \text{Normal}(0,\sigma^2)\\
            t_2\ _{df}\\
            \text{Uniform}(-b,b)
        \end{cases}$ where $q(\theta^c|\theta^o) = q(\theta^o|\theta^c) \Rightarrow \text{MHR}(\theta^o, \theta^c) = \frac{p(\theta^c)}{p(\theta^o)}$
        \subsubsection*{Independence proposals}
        $$\text{MHR}(\theta^o, \theta^c) = \frac{p(\theta^c)q(\theta^o)}{p(\theta^o)q(\theta^c)}$$
    \subsection*{Multidimentional $\Theta$: One-at-a-time updats}
    let $\Theta_U^{t+1},\Theta_0^{t} \subset \Theta$ be the set of updated or yet to be updated $\theta \in \Theta$. Then:
    $$\text{MHR}(\theta_i^t, \theta_i^c) = 
    \frac{p(\Theta_U^{t+1},\theta_i^c,\Theta_0^{t}\backslash \{\theta_i^c\}) q(\theta_i^t|\Theta_U^{t+1},\theta_i^c,\Theta_0^{t}\backslash \{\theta_i^c\})}
    {p(\Theta_U^{t+1},\Theta_0^{t}) q(\theta_i^c|\Theta_U^{t+1},\Theta_0^{t})}$$

\newpage
\section{MCMC Diagnostics}
    \subsection*{Notations}
        \begin{itemize}
            \item \textbf{Burn-in Length} $B$\\ The idea burn-in length $B$ is the point where the chain is converged (aka. future values will be in the limiting distribution)
            \item \textbf{Trace plots/Sample paths}\\ A time series plot of chains of generated values
        \end{itemize}
    \subsection*{Multiple Chains}
    The reason to plot multiple chains for a single random values is that a random variable $\theta$ may have multiple modes $\theta_1,...$, therefore we would like to capture as many as possible. A plot of such chains does not prove convergence, but instead can indicates a lack of convergence.
    \\~\\Let's say variables $\theta_1,...,\theta_K$ converge at $B = \{B_1,...,B_K\}$ respectively, then we say any sample length $N \geq \max B$ would indicates a "good mixing"
    \\~\\A more quantitive assesement of a good mixing/lack of convergence is the \textbf{Brooks-Gelman-Rubin} (BGR) statistics, and is defined as below:
    $$R = \frac{\text{Width of 80\% credible interval of all chains combined}}{\text{Average width of 80\% credible interval for each chain}}$$
    If the chain has converged, $R \approx 1$. If the chains have yet been converged then $R > 1$
    \subsection*{Variance of Monte Carlo Estimate $\MonteCarlo{\theta}$}
        \subsubsection*{Notation}
        \begin{itemize}
            \item $\gamma_k = \Cov{\theta^i,\theta^{i+k}}$: autocovariance of lag $k \geq 0$ of the chain
            \item $\sigma^2 = \gamma_0$: variance if the chain
            \item $\rho_k = \gamma_k / \sigma^2$: autocorrelation of lag $k$
            \item $\tau_n^2/n$: Variance of $\MonteCarlo{\theta}$
        \end{itemize}
        \begin{align*}
            \Var{\MonteCarlo{\theta}} &= \frac{\tau_n^2}{n}\\\tau_2^2 &= \sigma^2 \left[1 + 2 \sum_{k=1}^n \frac{n-k}{n}\rho_k\right]\ \text{(Ineffiency factor/ Integrated autocorrelation)}
        \end{align*}
        As $n \rightarrow \infty$:
        $$\tau_2^2 = \sigma^2 \left[1 + 2 \sum_{k=1}^n \frac{n-k}{n}\rho_k\right] \approx \sigma^2 \left(1 + 2 \sum_{k=1}^\infty \rho_k\right) \Rightarrow \Var{\MonteCarlo{\theta}} \approx \frac{\sigma^2 \left(1 + 2 \sum_{k=1}^\infty \rho_k\right)}{n}$$
        \newpage
        \subsubsection*{Effective Sample Size, ESS}
        $$n_{eff} = \frac{n}{1+ 2\sum_{k=1}^n\rho_k} \ \Rightarrow\ \Var{\MonteCarlo{\theta}} \approx \frac{\sigma^2}{n_{eff}}$$
        \subsubsection*{Autocorrelation Plots}
        $$\hat{\rho}_k = \frac{\hat{\gamma}_k}{\hat{\sigma^2}} = \frac{\sum_{i=1}^{n-1} \left(\theta^i - \bar{\theta}\right)\left(\theta^{i+k} - \bar{\theta}\right)}{\sum_{i=1}^n\left(\theta^i - \bar{\theta}\right)^2}, \quad \bar{\theta} \text{ is the sample average}$$
        \subsubsection*{Central Limit Theorem for $\MonteCarlo{\theta}$}
        $$\MonteCarlo{\theta} \sim \text{Asymptotically Normal}\left(\Expect{\theta}, \frac{\sigma^2}{n_{eff}}\right) \Rightarrow \frac{\MonteCarlo{\theta} - \Expect{\theta}}{\sigma/\sqrt{n_{eff}}} \sim \text{Normal}(0,1)$$
        \subsubsection*{Estimating $\Var{\MonteCarlo{\theta}}$}
        Batching is a popular method for estimating $\Var{\MonteCarlo{\theta}}$, whe algorithm is as below:
        \begin{enumerate}
            \item Partition chain of length $n$ into $m$ batches of $T\in [10,30]$ successive values
            \item For each batch calculate the mean of the values $\bar{\theta}_i$
            \item Estimate of $\Var{\MonteCarlo{\theta}}$ is then calculated:
                $$\hat{\frac{\tau^2}{n}} = \frac{\frac{T}{m-1}\sum_{i=1}^m\left(\bar{\theta}_i - \bar{\theta}\right)^2}{n}$$
        \end{enumerate}
        \subsubsection*{Improve Performance}
        \begin{itemize}
            \item Changing proposal distribution
            \item Reparameterising model
            \item Blocking
        \end{itemize}
    \newpage
    \subsection*{Gibbs Sampler}
    Can be seen as a special case of a Metropolis-Hasting sampler with two features:
    \begin{itemize}
        \item The proposal distributions are conditional distributions for $\theta$'s
        \item All candidates values are accepted (MHR$(\theta_i^t,\theta_i^c) = 1$)
    \end{itemize}
        \subsubsection*{The Algorithm}
        \begin{enumerate}
            \item Let $\Theta = (\theta_1,...,\theta_q) \sim p(\Theta)$
            \item For $i \in 1,..,q$ denote thr full conditional distribution for $\theta_i$ by
                $$p(\theta_i|\theta_{-i}) = p(\theta_i|\theta_1,...,\theta_{i-1}, \theta_{i+1},...,\theta_q)$$
            \item Initialise chain $\Theta^0 = (\theta_1^0,...,\theta_q^0)$
            \item At iteration $t+1$ given $\Theta^{t}$, $\Theta^{t+1}$ is generated as follows:
                \begin{itemize}[topsep = 0px]
                    \item Generate $\theta_1^{t+1}$ from $p(\theta_1|\theta_2^{t},...,\theta_q^{t})$
                    \\ \vdots
                    \item Generate $\theta_i^{t+1}$ from $p(\theta_i|\theta_1^{t+1},...,\theta_{i-1}^{t+1},\theta_{i+1}^{t},...,\theta_q^{t})$
                    \\ \vdots
                    \item Generate $\theta_q^{t+1}$ from $p(\theta_i|\theta_1^{t+1},...,\theta_{q-1}^{t+1})$
                \end{itemize}
            \item The (joint) transistion probability of going from $\Theta^t$ to $\Theta^{t+1}$ is:
                $$\mathcal{K}_{Gibbs}(\Theta^t,\Theta^{t+1}) = \prod_{i=1}^q p(\theta_i^{t+1}|\theta_j^{t+1}, j < i\ \cap\ \theta_j^{t}, j >i )$$
                An the stationary distribution is the target $p(\Theta)$
        \end{enumerate}
        \subsubsection*{Gibbs Sampler vs Metropolis-Hasting}
            \begin{multicols*}{2}
                \textbf{Gibbs Sampler}
                \begin{itemize}
                    \item Strengths
                    \begin{itemize}[topsep = 0pt]
                        \item Automatically defined proposal dist.
                        \item Accepts all candidate values
                        \item views as an "adaptive algorithm"
                    \end{itemize}
                    \item Weaknesses
                    \begin{itemize}[topsep = 0pt]
                        \item Conditional distribution may not be tractable
                        \item Sampling may be computationally intensive
                        \item 100\% acceptance $\neq$ good mizing
                    \end{itemize}
                \end{itemize}
                \vfill\null
                \columnbreak
                \textbf{Metropolis Hasting}
                \begin{itemize}
                    \item Strengths
                    \begin{itemize}[topsep = 0pt]
                        \item flexible proposal dist., can be fast sample from, fast to evaluate MHR
                        \item Don't need to know conditional dist.
                        \item easily block updating
                    \end{itemize}
                    \item Weaknesses
                    \begin{itemize}[topsep = 0pt]
                        \item Hard to find good proposal with good mixing
                        \item Can take time to tune a proposal
                    \end{itemize}
                \end{itemize}
            \end{multicols*}
\end{document}